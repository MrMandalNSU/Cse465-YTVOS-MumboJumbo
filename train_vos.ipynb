{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_vos.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMolunYIxEM6jMW/Ajb3NHL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5a556db449bc4c4f93e1dd91b929bbd7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_70bec3b9e313459fa5227af1aa97566b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fdd623715f3242c09ee46edf61729055","IPY_MODEL_66bcd9e9e3c34d84a254001fbd314256"]}},"70bec3b9e313459fa5227af1aa97566b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fdd623715f3242c09ee46edf61729055":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ca3a2e245a9744308ab4b1a551239ac5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":553433881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":553433881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f98adb166b49424da2a1d6306cc652ba"}},"66bcd9e9e3c34d84a254001fbd314256":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b0e865cf5c7c4a73a923ee8a00dd0d95","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528M/528M [00:02&lt;00:00, 210MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a90be274c552487d8a53bd61c88375fc"}},"ca3a2e245a9744308ab4b1a551239ac5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f98adb166b49424da2a1d6306cc652ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0e865cf5c7c4a73a923ee8a00dd0d95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a90be274c552487d8a53bd61c88375fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fdqBxusX1oTJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611335770164,"user_tz":-360,"elapsed":35673,"user":{"displayName":"Shad Al Kaiser 1721392","photoUrl":"https://lh3.googleusercontent.com/-rPvi92Sp3JA/AAAAAAAAAAI/AAAAAAAAABs/AitIsFEo26g/s64/photo.jpg","userId":"02257860417479013950"}},"outputId":"5a0b285b-49f1-40dd-c32f-19ea89ab69a6"},"source":["colab = True\r\n","if colab:\r\n","    # Mount drive\r\n","    from google.colab import drive\r\n","    drive.mount('/content/gdrive')\r\n","    # Set path to working directory\r\n","    import sys\r\n","    sys.path.append('/content/gdrive/My Drive/VOS/')\r\n","    %cd /content/gdrive/My\\ Drive/VOS/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/VOS\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5a556db449bc4c4f93e1dd91b929bbd7","70bec3b9e313459fa5227af1aa97566b","fdd623715f3242c09ee46edf61729055","66bcd9e9e3c34d84a254001fbd314256","ca3a2e245a9744308ab4b1a551239ac5","f98adb166b49424da2a1d6306cc652ba","b0e865cf5c7c4a73a923ee8a00dd0d95","a90be274c552487d8a53bd61c88375fc"]},"id":"l5sVg9bE2OKT","executionInfo":{"status":"ok","timestamp":1611337418565,"user_tz":-360,"elapsed":1604340,"user":{"displayName":"Shad Al Kaiser 1721392","photoUrl":"https://lh3.googleusercontent.com/-rPvi92Sp3JA/AAAAAAAAAAI/AAAAAAAAABs/AitIsFEo26g/s64/photo.jpg","userId":"02257860417479013950"}},"outputId":"e20f22c9-70b2-4723-a092-9d50e3f5a7c8"},"source":["import os\r\n","import sys\r\n","import numpy as np\r\n","import cv2\r\n","import json\r\n","import random\r\n","import torch\r\n","import torch.utils.data\r\n","import torchvision.models as models\r\n","from torch import nn, optim\r\n","from torch.autograd import Variable\r\n","from torch.utils.data import DataLoader\r\n","from torch.nn import functional as F\r\n","from torch.utils.data.dataset import Dataset\r\n","from torchvision import datasets, transforms\r\n","from torchvision.utils import save_image\r\n","from PIL import Image\r\n","import matplotlib.pyplot as plt\r\n","from skimage import io\r\n","import matplotlib.pyplot as plt\r\n","from PIL import Image\r\n","import glob\r\n","from torchvision.utils import save_image\r\n","import configuration as cfg\r\n","from utils.dataloader5fps import dataLoader_5fps\r\n","from utils.initializer import Initializer, Encoder, Decoder\r\n","from utils.convlstm import *\r\n","from utils.ensemble import *\r\n","\r\n","# added by Team-MumboJumbo\r\n","import router\r\n","\r\n","batch_size = 4\r\n","epoch = cfg.epoch\r\n","\r\n","transform_rgb = transforms.Compose([\r\n","    transforms.Resize(256),\r\n","    transforms.CenterCrop((256, 448)),\r\n","    transforms.ToTensor(),\r\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\r\n","\r\n","transforms_seg = transforms.Compose([\r\n","    transforms.Resize(256),\r\n","    transforms.CenterCrop((256, 448)),\r\n","    transforms.ToTensor()])\r\n","\r\n","dset_train = dataLoader_5fps(cfg.JPEGtrain_5fps, cfg.Anntrain_5fps, cfg.json_path, transform_rgb, transforms_seg)\r\n","\r\n","train_loader = DataLoader(dset_train,\r\n","                          batch_size=batch_size,\r\n","                          shuffle=True)\r\n","\r\n","initializer = Initializer()\r\n","encoder = Encoder()\r\n","convlstm = ConvLSTMCell(input_size=512,\r\n","                        hidden_size=512)\r\n","decoder = Decoder()\r\n","\r\n","model = MyEnsemble(initializer, encoder, convlstm, decoder)\r\n","\r\n","if cfg.cuda_enable:\r\n","    model.cuda()\r\n","\r\n","# print(model)\r\n","\r\n","\r\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\r\n","\r\n","\r\n","def train(epoch):\r\n","    # optimizer =exp_lr_scheduler(optim.Adam(model.parameters()), epoch, init_lr=0.0001, lr_decay_epoch=30)\r\n","    model.train()\r\n","    train_loss = 0\r\n","    for batch_idx, (initialMask, initialRGB, segData, rgbData) in enumerate(train_loader):\r\n","        if cfg.cuda_enable:\r\n","            rgb = Variable(initialRGB).cuda()\r\n","            mask = Variable(initialMask).cuda()\r\n","            rgbData = Variable(rgbData).type(torch.FloatTensor).cuda()\r\n","            maskData = Variable(segData).type(torch.FloatTensor).cuda()\r\n","        else:\r\n","            rgb = Variable(initialRGB)\r\n","            mask = Variable(initialMask)\r\n","            rgbData = Variable(rgbData).type(torch.FloatTensor)\r\n","            maskData = Variable(segData).type(torch.FloatTensor)\r\n","\r\n","        output = model(rgb, mask, rgbData)\r\n","        optimizer.zero_grad()\r\n","\r\n","        loss = F.binary_cross_entropy(output, maskData)\r\n","\r\n","        loss.backward()\r\n","        train_loss += loss.item()\r\n","        optimizer.step()\r\n","\r\n","        temp = torch.cat((output[:, 1, :, :, :], maskData[:, 1, :, :, :]), 0)\r\n","\r\n","        \r\n","\r\n","        # block added by Team-MumboJumbo\r\n","        recons_path = os.path.join(router.data_root, 'recons_{}.png'.format(epoch))\r\n","        save_image(temp, recons_path)\r\n","\r\n","        if batch_idx % 1 == 0:\r\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n","                epoch, batch_idx * len(initialMask), len(train_loader.dataset),\r\n","                       100. * batch_idx / len(train_loader),\r\n","                       loss.item() / len(initialMask)))\r\n","\r\n","    print('================> Epoch: {} Average loss: {:.4f}'.format(\r\n","        epoch, train_loss / len(train_loader.dataset)))\r\n","\r\n","    if (epoch % 1 == 0):\r\n","    \r\n","\r\n","        # block added by Team-MumboJumbo\r\n","        model_path = os.path.join(router.model_root, 'youtubeVOSModel_trial_3_{}.pth'.format(epoch))\r\n","        torch.save(model.state_dict(), model_path)\r\n","\r\n","\r\n","for epochs in range(1, epoch + 1):\r\n","    train(epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a556db449bc4c4f93e1dd91b929bbd7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Train Epoch: 1 [0/10 (0%)]\tLoss: 0.175324\n","Train Epoch: 1 [4/10 (33%)]\tLoss: 0.175508\n","Train Epoch: 1 [4/10 (67%)]\tLoss: 0.350926\n","================> Epoch: 1 Average loss: 0.2105\n","Train Epoch: 2 [0/10 (0%)]\tLoss: 0.175604\n","Train Epoch: 2 [4/10 (33%)]\tLoss: 0.175356\n","Train Epoch: 2 [4/10 (67%)]\tLoss: 0.349566\n","================> Epoch: 2 Average loss: 0.2103\n","Train Epoch: 3 [0/10 (0%)]\tLoss: 0.175063\n","Train Epoch: 3 [4/10 (33%)]\tLoss: 0.175491\n","Train Epoch: 3 [4/10 (67%)]\tLoss: 0.350306\n","================> Epoch: 3 Average loss: 0.2103\n","Train Epoch: 4 [0/10 (0%)]\tLoss: 0.175554\n","Train Epoch: 4 [4/10 (33%)]\tLoss: 0.175228\n","Train Epoch: 4 [4/10 (67%)]\tLoss: 0.349540\n","================> Epoch: 4 Average loss: 0.2102\n","Train Epoch: 5 [0/10 (0%)]\tLoss: 0.175037\n","Train Epoch: 5 [4/10 (33%)]\tLoss: 0.175354\n","Train Epoch: 5 [4/10 (67%)]\tLoss: 0.350718\n","================> Epoch: 5 Average loss: 0.2103\n","Train Epoch: 6 [0/10 (0%)]\tLoss: 0.175045\n","Train Epoch: 6 [4/10 (33%)]\tLoss: 0.175060\n","Train Epoch: 6 [4/10 (67%)]\tLoss: 0.349716\n","================> Epoch: 6 Average loss: 0.2100\n","Train Epoch: 7 [0/10 (0%)]\tLoss: 0.174976\n","Train Epoch: 7 [4/10 (33%)]\tLoss: 0.175162\n","Train Epoch: 7 [4/10 (67%)]\tLoss: 0.349365\n","================> Epoch: 7 Average loss: 0.2099\n","Train Epoch: 8 [0/10 (0%)]\tLoss: 0.174609\n","Train Epoch: 8 [4/10 (33%)]\tLoss: 0.175090\n","Train Epoch: 8 [4/10 (67%)]\tLoss: 0.349733\n","================> Epoch: 8 Average loss: 0.2098\n","Train Epoch: 9 [0/10 (0%)]\tLoss: 0.174416\n","Train Epoch: 9 [4/10 (33%)]\tLoss: 0.174585\n","Train Epoch: 9 [4/10 (67%)]\tLoss: 0.348625\n","================> Epoch: 9 Average loss: 0.2093\n","Train Epoch: 10 [0/10 (0%)]\tLoss: 0.173742\n","Train Epoch: 10 [4/10 (33%)]\tLoss: 0.173409\n","Train Epoch: 10 [4/10 (67%)]\tLoss: 0.344170\n","================> Epoch: 10 Average loss: 0.2077\n","Train Epoch: 11 [0/10 (0%)]\tLoss: 0.169356\n","Train Epoch: 11 [4/10 (33%)]\tLoss: 0.170547\n","Train Epoch: 11 [4/10 (67%)]\tLoss: 0.336696\n","================> Epoch: 11 Average loss: 0.2033\n","Train Epoch: 12 [0/10 (0%)]\tLoss: 0.161808\n","Train Epoch: 12 [4/10 (33%)]\tLoss: 0.158673\n","Train Epoch: 12 [4/10 (67%)]\tLoss: 0.294194\n","================> Epoch: 12 Average loss: 0.1870\n","Train Epoch: 13 [0/10 (0%)]\tLoss: 0.139975\n","Train Epoch: 13 [4/10 (33%)]\tLoss: 0.160208\n","Train Epoch: 13 [4/10 (67%)]\tLoss: 0.286317\n","================> Epoch: 13 Average loss: 0.1773\n","Train Epoch: 14 [0/10 (0%)]\tLoss: 0.147284\n","Train Epoch: 14 [4/10 (33%)]\tLoss: 0.120923\n","Train Epoch: 14 [4/10 (67%)]\tLoss: 0.344397\n","================> Epoch: 14 Average loss: 0.1762\n","Train Epoch: 15 [0/10 (0%)]\tLoss: 0.180339\n","Train Epoch: 15 [4/10 (33%)]\tLoss: 0.125317\n","Train Epoch: 15 [4/10 (67%)]\tLoss: 0.194376\n","================> Epoch: 15 Average loss: 0.1611\n","Train Epoch: 16 [0/10 (0%)]\tLoss: 0.141188\n","Train Epoch: 16 [4/10 (33%)]\tLoss: 0.112854\n","Train Epoch: 16 [4/10 (67%)]\tLoss: 0.324807\n","================> Epoch: 16 Average loss: 0.1666\n","Train Epoch: 17 [0/10 (0%)]\tLoss: 0.138367\n","Train Epoch: 17 [4/10 (33%)]\tLoss: 0.130745\n","Train Epoch: 17 [4/10 (67%)]\tLoss: 0.227891\n","================> Epoch: 17 Average loss: 0.1532\n","Train Epoch: 18 [0/10 (0%)]\tLoss: 0.129910\n","Train Epoch: 18 [4/10 (33%)]\tLoss: 0.158004\n","Train Epoch: 18 [4/10 (67%)]\tLoss: 0.206277\n","================> Epoch: 18 Average loss: 0.1564\n","Train Epoch: 19 [0/10 (0%)]\tLoss: 0.129212\n","Train Epoch: 19 [4/10 (33%)]\tLoss: 0.120584\n","Train Epoch: 19 [4/10 (67%)]\tLoss: 0.251662\n","================> Epoch: 19 Average loss: 0.1503\n","Train Epoch: 20 [0/10 (0%)]\tLoss: 0.152229\n","Train Epoch: 20 [4/10 (33%)]\tLoss: 0.131132\n","Train Epoch: 20 [4/10 (67%)]\tLoss: 0.172642\n","================> Epoch: 20 Average loss: 0.1479\n","Train Epoch: 21 [0/10 (0%)]\tLoss: 0.125841\n","Train Epoch: 21 [4/10 (33%)]\tLoss: 0.117479\n","Train Epoch: 21 [4/10 (67%)]\tLoss: 0.185551\n","================> Epoch: 21 Average loss: 0.1344\n","Train Epoch: 22 [0/10 (0%)]\tLoss: 0.108259\n","Train Epoch: 22 [4/10 (33%)]\tLoss: 0.117023\n","Train Epoch: 22 [4/10 (67%)]\tLoss: 0.213714\n","================> Epoch: 22 Average loss: 0.1329\n","Train Epoch: 23 [0/10 (0%)]\tLoss: 0.138027\n","Train Epoch: 23 [4/10 (33%)]\tLoss: 0.128918\n","Train Epoch: 23 [4/10 (67%)]\tLoss: 0.132834\n","================> Epoch: 23 Average loss: 0.1333\n","Train Epoch: 24 [0/10 (0%)]\tLoss: 0.141818\n","Train Epoch: 24 [4/10 (33%)]\tLoss: 0.087664\n","Train Epoch: 24 [4/10 (67%)]\tLoss: 0.227033\n","================> Epoch: 24 Average loss: 0.1372\n","Train Epoch: 25 [0/10 (0%)]\tLoss: 0.103851\n","Train Epoch: 25 [4/10 (33%)]\tLoss: 0.120982\n","Train Epoch: 25 [4/10 (67%)]\tLoss: 0.216967\n","================> Epoch: 25 Average loss: 0.1333\n","Train Epoch: 26 [0/10 (0%)]\tLoss: 0.099870\n","Train Epoch: 26 [4/10 (33%)]\tLoss: 0.102914\n","Train Epoch: 26 [4/10 (67%)]\tLoss: 0.199138\n","================> Epoch: 26 Average loss: 0.1209\n","Train Epoch: 27 [0/10 (0%)]\tLoss: 0.081710\n","Train Epoch: 27 [4/10 (33%)]\tLoss: 0.107622\n","Train Epoch: 27 [4/10 (67%)]\tLoss: 0.287914\n","================> Epoch: 27 Average loss: 0.1333\n","Train Epoch: 28 [0/10 (0%)]\tLoss: 0.086743\n","Train Epoch: 28 [4/10 (33%)]\tLoss: 0.091203\n","Train Epoch: 28 [4/10 (67%)]\tLoss: 0.211601\n","================> Epoch: 28 Average loss: 0.1135\n","Train Epoch: 29 [0/10 (0%)]\tLoss: 0.094465\n","Train Epoch: 29 [4/10 (33%)]\tLoss: 0.103981\n","Train Epoch: 29 [4/10 (67%)]\tLoss: 0.212130\n","================> Epoch: 29 Average loss: 0.1218\n","Train Epoch: 30 [0/10 (0%)]\tLoss: 0.088110\n","Train Epoch: 30 [4/10 (33%)]\tLoss: 0.082833\n","Train Epoch: 30 [4/10 (67%)]\tLoss: 0.169470\n","================> Epoch: 30 Average loss: 0.1023\n","Train Epoch: 31 [0/10 (0%)]\tLoss: 0.103701\n","Train Epoch: 31 [4/10 (33%)]\tLoss: 0.069172\n","Train Epoch: 31 [4/10 (67%)]\tLoss: 0.107402\n","================> Epoch: 31 Average loss: 0.0906\n","Train Epoch: 32 [0/10 (0%)]\tLoss: 0.077458\n","Train Epoch: 32 [4/10 (33%)]\tLoss: 0.117739\n","Train Epoch: 32 [4/10 (67%)]\tLoss: 0.201298\n","================> Epoch: 32 Average loss: 0.1183\n","Train Epoch: 33 [0/10 (0%)]\tLoss: 0.058582\n","Train Epoch: 33 [4/10 (33%)]\tLoss: 0.094653\n","Train Epoch: 33 [4/10 (67%)]\tLoss: 0.180488\n","================> Epoch: 33 Average loss: 0.0974\n","Train Epoch: 34 [0/10 (0%)]\tLoss: 0.076925\n","Train Epoch: 34 [4/10 (33%)]\tLoss: 0.092912\n","Train Epoch: 34 [4/10 (67%)]\tLoss: 0.234370\n","================> Epoch: 34 Average loss: 0.1148\n","Train Epoch: 35 [0/10 (0%)]\tLoss: 0.073682\n","Train Epoch: 35 [4/10 (33%)]\tLoss: 0.085238\n","Train Epoch: 35 [4/10 (67%)]\tLoss: 0.112077\n","================> Epoch: 35 Average loss: 0.0860\n","Train Epoch: 36 [0/10 (0%)]\tLoss: 0.059685\n","Train Epoch: 36 [4/10 (33%)]\tLoss: 0.056253\n","Train Epoch: 36 [4/10 (67%)]\tLoss: 0.193702\n","================> Epoch: 36 Average loss: 0.0851\n","Train Epoch: 37 [0/10 (0%)]\tLoss: 0.072066\n","Train Epoch: 37 [4/10 (33%)]\tLoss: 0.097117\n","Train Epoch: 37 [4/10 (67%)]\tLoss: 0.134503\n","================> Epoch: 37 Average loss: 0.0946\n","Train Epoch: 38 [0/10 (0%)]\tLoss: 0.056558\n","Train Epoch: 38 [4/10 (33%)]\tLoss: 0.079284\n","Train Epoch: 38 [4/10 (67%)]\tLoss: 0.096001\n","================> Epoch: 38 Average loss: 0.0735\n","Train Epoch: 39 [0/10 (0%)]\tLoss: 0.066272\n","Train Epoch: 39 [4/10 (33%)]\tLoss: 0.094067\n","Train Epoch: 39 [4/10 (67%)]\tLoss: 0.084120\n","================> Epoch: 39 Average loss: 0.0810\n","Train Epoch: 40 [0/10 (0%)]\tLoss: 0.066216\n","Train Epoch: 40 [4/10 (33%)]\tLoss: 0.084452\n","Train Epoch: 40 [4/10 (67%)]\tLoss: 0.072968\n","================> Epoch: 40 Average loss: 0.0749\n","Train Epoch: 41 [0/10 (0%)]\tLoss: 0.076259\n","Train Epoch: 41 [4/10 (33%)]\tLoss: 0.070863\n","Train Epoch: 41 [4/10 (67%)]\tLoss: 0.102769\n","================> Epoch: 41 Average loss: 0.0794\n","Train Epoch: 42 [0/10 (0%)]\tLoss: 0.052281\n","Train Epoch: 42 [4/10 (33%)]\tLoss: 0.066142\n","Train Epoch: 42 [4/10 (67%)]\tLoss: 0.124982\n","================> Epoch: 42 Average loss: 0.0724\n","Train Epoch: 43 [0/10 (0%)]\tLoss: 0.080068\n","Train Epoch: 43 [4/10 (33%)]\tLoss: 0.034228\n","Train Epoch: 43 [4/10 (67%)]\tLoss: 0.138046\n","================> Epoch: 43 Average loss: 0.0733\n","Train Epoch: 44 [0/10 (0%)]\tLoss: 0.067841\n","Train Epoch: 44 [4/10 (33%)]\tLoss: 0.075729\n","Train Epoch: 44 [4/10 (67%)]\tLoss: 0.059497\n","================> Epoch: 44 Average loss: 0.0693\n","Train Epoch: 45 [0/10 (0%)]\tLoss: 0.052119\n","Train Epoch: 45 [4/10 (33%)]\tLoss: 0.040188\n","Train Epoch: 45 [4/10 (67%)]\tLoss: 0.127065\n","================> Epoch: 45 Average loss: 0.0623\n","Train Epoch: 46 [0/10 (0%)]\tLoss: 0.064459\n","Train Epoch: 46 [4/10 (33%)]\tLoss: 0.063686\n","Train Epoch: 46 [4/10 (67%)]\tLoss: 0.097599\n","================> Epoch: 46 Average loss: 0.0708\n","Train Epoch: 47 [0/10 (0%)]\tLoss: 0.055482\n","Train Epoch: 47 [4/10 (33%)]\tLoss: 0.049889\n","Train Epoch: 47 [4/10 (67%)]\tLoss: 0.070426\n","================> Epoch: 47 Average loss: 0.0562\n","Train Epoch: 48 [0/10 (0%)]\tLoss: 0.037640\n","Train Epoch: 48 [4/10 (33%)]\tLoss: 0.072158\n","Train Epoch: 48 [4/10 (67%)]\tLoss: 0.123763\n","================> Epoch: 48 Average loss: 0.0687\n","Train Epoch: 49 [0/10 (0%)]\tLoss: 0.045237\n","Train Epoch: 49 [4/10 (33%)]\tLoss: 0.041571\n","Train Epoch: 49 [4/10 (67%)]\tLoss: 0.143195\n","================> Epoch: 49 Average loss: 0.0634\n","Train Epoch: 50 [0/10 (0%)]\tLoss: 0.046503\n","Train Epoch: 50 [4/10 (33%)]\tLoss: 0.076006\n","Train Epoch: 50 [4/10 (67%)]\tLoss: 0.051000\n","================> Epoch: 50 Average loss: 0.0592\n"],"name":"stdout"}]}]}